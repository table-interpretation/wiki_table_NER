{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e7da456",
   "metadata": {},
   "source": [
    "### In this notebook we calculate the statistics of the existing datasets and the Wiki_TabNER dataset. The final table is at the end of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fd2c33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "import spacy\n",
    "import tqdm\n",
    "import csv\n",
    "import os\n",
    "from scipy.stats import kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e84c24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "354c81ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10c736b",
   "metadata": {},
   "source": [
    "##### To download the spacy model, use the following command: python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bcb9984",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad1a8337",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = 'Unforgiven – Clint Eastwood A Few Good Men – Rob Reiner , Andrew Scheinman Howards End – Ismail Merchant Scent of a Woman – Martin Brest The Crying Game – Stephen Woolley'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4472bb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([tok for tok in nlp(str(cell))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5065eb85",
   "metadata": {},
   "source": [
    "### Wikitables analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1149fd05",
   "metadata": {},
   "source": [
    "We first analyse the WikiTables corpus. We calculate the number of links per cell in the tables. We want to extract how many of the total number of cells in the WikiTables corpus, have 2 or more links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec357081",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_wikitables = \"../data/original_dataset/tables.json\"\n",
    "wiki_links_ids = \"../data/original_dataset/wiki_links-random.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd0548b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze entity counts in a batch\n",
    "def analyze_batch(batch_data):\n",
    "    entity_counts = []    \n",
    "    \n",
    "    for table in batch_data:\n",
    "        table_data = table['tableData']\n",
    "       \n",
    "        for row in table_data:\n",
    "            for cell in row:       \n",
    "                if len(cell[\"surfaceLinks\"])>0:\n",
    "                    entity_counts.append(len(cell[\"surfaceLinks\"]))\n",
    "                else:\n",
    "                    entity_counts.append(0)\n",
    "                    \n",
    "    return pd.Series(entity_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aeb092",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"../data/original_dataset/tables.json\", \"r\") as file:\n",
    "\n",
    "    batch_size = 1500000  \n",
    "    batch_data = [json.loads(next(file)) for _ in range(batch_size)]\n",
    "    total_entity_counts = pd.Series()\n",
    "\n",
    "    batch_entity_counts = analyze_batch(batch_data)\n",
    "    total_entity_counts = pd.concat([total_entity_counts, batch_entity_counts])\n",
    "    \n",
    "total_entity_counts.to_csv(\"wiki_tables_entity_count.csv\")\n",
    "stats_all_batches = total_entity_counts.describe()\n",
    "\n",
    "print(\"Summary Statistics on Entity Counts for All Batches:\")\n",
    "print(stats_all_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "363071f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_entity_counts = pd.read_csv(\"../wiki_tables_entity_count.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d85ebd87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93957683"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_entity_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "408ddbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"cell\", \"num_ent\"]\n",
    "total_entity_counts.columns = column_names\n",
    "del total_entity_counts[\"cell\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4701c075",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_zeros=total_entity_counts.loc[total_entity_counts.num_ent>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf380674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24206485"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_zeros) # 25 percent of all cells have at least 1 link, 4% of all have at least 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da9f2a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.420648e+07\n",
       "mean     1.319904e+00\n",
       "std      2.544662e+00\n",
       "min      1.000000e+00\n",
       "25%      1.000000e+00\n",
       "50%      1.000000e+00\n",
       "75%      1.000000e+00\n",
       "max      9.170000e+02\n",
       "Name: num_ent, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_zeros['num_ent'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d25eb902",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_than_1=no_zeros.loc[no_zeros.num_ent>2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99f6821f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "896039"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(more_than_1) # 3.7 percent of all cells have more than 2 links per cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf50188",
   "metadata": {},
   "source": [
    "### Other datasets analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cf6491",
   "metadata": {},
   "source": [
    "The T2D, Limaye and WikiGS datasets are downloaded from http://www.cs.toronto.edu/~oktie/webtables/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd52528",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2d_path = \"../Efthymiou_datasets/webtables-evaluation-data/csv/t2d_tables_instance/\"\n",
    "limaye_path = \"../Efthymiou_datasets/webtables-evaluation-data/csv/LimayeGS/tables_instance/\"\n",
    "wiki_gold_standard_path = \"../Efthymiou_datasets/webtables-evaluation-data/csv/WikipediaGS/tables_instance/csv/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ae73a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "git_path = \"../data/other_data/Git_tables/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da51a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sato_path = \"../data/other_data/sato_tables/all/K0/\" #itterate here over the K splits and calc avg stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a52d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random selection of 15000 tables for analysis\n",
    "dfs_wiki = load_tables(wiki_gold_standard_path)\n",
    "dfs_wiki = dfs_wiki[100000:115000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4f34e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tables(folder_path):\n",
    "    dfs = []\n",
    "    csv_files = [f for f in os.listdir(folder_path) ]\n",
    "    for csv_file in csv_files:\n",
    "        file_path = os.path.join(folder_path, csv_file)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, engine='python', on_bad_lines='skip')\n",
    "            dfs.append(df)\n",
    "        except pd.errors.EmptyDataError as e:\n",
    "                print(f\"No data found in CSV file: {csv_file}\")\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "da1359e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_stats(dfs):\n",
    "    \n",
    "    stats = {\"mean_num_rows\":0, \"std_num_rows\":0, \"mean_num_cols\":0, \"std_num_cols\":0, \"mean_num_toks\":0, \"std_num_toks\":0, \"kurtosis\":0}\n",
    "    overall_num_rows = []\n",
    "    overall_num_cols = []\n",
    "    overall_num_toks = []\n",
    "    overall_info_dens = []\n",
    "    num_ents_comma = []\n",
    "    \n",
    "    for df in dfs:\n",
    "        \n",
    "        named_ents = named_entities_cell[i]\n",
    "        \n",
    "        num_cols = len(df.columns)\n",
    "        num_rows = len(df)\n",
    "\n",
    "        overall_num_rows.append(num_rows)\n",
    "        overall_num_cols.append(num_cols)\n",
    "\n",
    "        for index,row in df.iterrows():\n",
    "            for col in df.columns:  \n",
    "             \n",
    "                cell_text = row[col]\n",
    "                \n",
    "                ents_comma = str(cell_text).split(\",\")\n",
    "                num_ents_comma.append(len(ents_comma))\n",
    "\n",
    "                num_tokens = len([tok for tok in nlp(str(cell_text))])            \n",
    "                overall_num_toks.append(num_tokens)\n",
    "                \n",
    "    stats[\"mean_num_rows\"] = np.mean(overall_num_rows)\n",
    "    stats[\"std_num_rows\"] = np.std(overall_num_rows)\n",
    "\n",
    "    stats[\"mean_num_cols\"] = np.mean(overall_num_cols)\n",
    "    stats[\"std_num_cols\"] = np.std(overall_num_cols)\n",
    "    \n",
    "    stats[\"mean_num_toks\"] = np.mean(overall_num_toks)\n",
    "    stats[\"std_num_toks\"] = np.std(overall_num_toks)\n",
    "\n",
    "    stats[\"mean_comma\"] = np.mean(num_ents_comma)\n",
    "    stats[\"std_comma\"] = np.std(num_ents_comma)\n",
    "        \n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8ef5c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stats(dataset_name, file_path, final_stats_df):    \n",
    "        \n",
    "    #dfs = load_tables(file_path)    \n",
    "    print(len(dfs))\n",
    "    stats = compute_stats(dfs)\n",
    "    \n",
    "    stats_df =  pd.DataFrame([stats])\n",
    "    stats_df[\"dataset\"] = dataset_name\n",
    "    stats_df[\"num_tables\"] = len(dfs)\n",
    "    \n",
    "    df_final = pd.concat([final_stats_df, stats_df], ignore_index=True)\n",
    "    \n",
    "    df_final.to_csv(\"overall_dataset_stats.csv\")\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa9d7ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load current stats to add new \n",
    "current_stats = pd.read_csv(\"overall_dataset_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6217c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "added_wikiGS = add_stats(\"WikiGS\", wiki_gold_standard_path, added_sato0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cc75ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the mean over the data split from SATO\n",
    "\n",
    "only_sato = added_sato0[added_sato0['dataset'].str.contains(\"sato\")]\n",
    "mean_row = only_sato[numeric_columns].mean(axis=0)\n",
    "mean_row['num_tables'] = only_sato['num_tables'].sum(axis=0)\n",
    "mean_row['dataset'] = \"sato_multi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fbf4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "added_sato0.loc[12] = mean_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cf5f0e",
   "metadata": {},
   "source": [
    "### TURL entity linking eval dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83115048",
   "metadata": {},
   "source": [
    "The link for donloading the TURL data can be found in their github repository: https://github.com/sunlab-osu/TURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b403699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar for the test_own.table_entity_linking.json\n",
    "with open(os.path.join('../turl_dataset', 'dev.table_entity_linking.json'), 'r') as f:\n",
    "    turl_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89984aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "added_turl = add_stats(\"turl_el_dev\", turl_dataset, current_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94b60a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "turl_el = added_turl.loc[added_turl['dataset']==\"turl_el\"]\n",
    "turl_el_dev= added_turl.loc[added_turl['dataset']==\"turl_el_dev\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efec5814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the mean over the dev and test data from TURL\n",
    "merged_df = pd.concat([turl_el, turl_el_dev])\n",
    "mean_row = merged_df[numeric_columns].mean(axis=0)\n",
    "\n",
    "turl_mean = mean_row.to_dict()\n",
    "turl_mean['num_tables'] = 10927 # this is the sum of the dev and test tables\n",
    "turl_mean['dataset'] = \"turl_el_test_dev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5025e38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "added_turl.loc[7] = turl_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff93134",
   "metadata": {},
   "outputs": [],
   "source": [
    "added_turl.to_csv(\"overall_dataset_stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b4a7be",
   "metadata": {},
   "source": [
    "### Wiki_TabNER analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dceab173",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabner_data_path=\"../data/Wiki_TabNER_final_labeled.json\"\n",
    "with open(tabner_data_path, 'r') as f:\n",
    "    ner_tables = json.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4af3adc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "named_entities_cell = []\n",
    "for i in range(len(ner_tables)):\n",
    "  \n",
    "    tableHeaders = ner_tables[i][0][4]\n",
    "    table_data = ner_tables[i][0][5]    \n",
    "    \n",
    "    named_entities_cell.append(ner_tables[i][0][6])\n",
    "    \n",
    "    columns = [tableHeaders[i] for i in range(len(tableHeaders))]\n",
    " \n",
    "    row_indexes = [item[0][0] for item in table_data]\n",
    "    col_indexes = [item[0][1] for item in table_data]\n",
    "    values = [item[1] for item in table_data]\n",
    "\n",
    "    # Create a dictionary to hold the data\n",
    "    data_dict = {}\n",
    "    for row_idx, col_idx, value in zip(row_indexes, col_indexes, values):\n",
    "        if row_idx not in data_dict:\n",
    "            data_dict[row_idx] = {}\n",
    "        data_dict[row_idx][col_idx] = value\n",
    "\n",
    "    df = pd.DataFrame.from_dict(data_dict, orient='index')\n",
    "   \n",
    "    df.index.name = None\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57f70007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61273\n"
     ]
    }
   ],
   "source": [
    "added_tabner = add_stats(\"wiki_tabner_final\", tabner_data_path, current_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57fc704",
   "metadata": {},
   "source": [
    "### Final datasets statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ef34131",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_stats = pd.read_csv(\"overall_dataset_stats.csv\")\n",
    "current_stats.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "34f31377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>num_tables</th>\n",
       "      <th>mean_num_rows</th>\n",
       "      <th>std_num_rows</th>\n",
       "      <th>mean_num_cols</th>\n",
       "      <th>std_num_cols</th>\n",
       "      <th>mean_num_toks</th>\n",
       "      <th>std_num_toks</th>\n",
       "      <th>mean_comma</th>\n",
       "      <th>std_comma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>WikiGS</td>\n",
       "      <td>15000</td>\n",
       "      <td>13.783733</td>\n",
       "      <td>35.450495</td>\n",
       "      <td>4.578733</td>\n",
       "      <td>3.356179</td>\n",
       "      <td>2.471672</td>\n",
       "      <td>5.704536</td>\n",
       "      <td>1.103979</td>\n",
       "      <td>0.618069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>git_tables</td>\n",
       "      <td>1101</td>\n",
       "      <td>58.196185</td>\n",
       "      <td>94.693164</td>\n",
       "      <td>16.873751</td>\n",
       "      <td>11.600740</td>\n",
       "      <td>1.868231</td>\n",
       "      <td>10.062218</td>\n",
       "      <td>1.037563</td>\n",
       "      <td>0.617178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>limaye</td>\n",
       "      <td>428</td>\n",
       "      <td>34.549065</td>\n",
       "      <td>40.992761</td>\n",
       "      <td>3.787383</td>\n",
       "      <td>1.233917</td>\n",
       "      <td>1.706675</td>\n",
       "      <td>1.392773</td>\n",
       "      <td>1.033316</td>\n",
       "      <td>0.182750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sato_K0</td>\n",
       "      <td>15736</td>\n",
       "      <td>17.848310</td>\n",
       "      <td>60.938394</td>\n",
       "      <td>1.530249</td>\n",
       "      <td>0.787049</td>\n",
       "      <td>2.936658</td>\n",
       "      <td>9.177716</td>\n",
       "      <td>1.123136</td>\n",
       "      <td>1.106772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sato_K1</td>\n",
       "      <td>15754</td>\n",
       "      <td>18.480640</td>\n",
       "      <td>75.620203</td>\n",
       "      <td>1.531801</td>\n",
       "      <td>0.785103</td>\n",
       "      <td>2.995293</td>\n",
       "      <td>8.307041</td>\n",
       "      <td>1.127742</td>\n",
       "      <td>0.741978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sato_K2</td>\n",
       "      <td>15776</td>\n",
       "      <td>17.669118</td>\n",
       "      <td>54.755346</td>\n",
       "      <td>1.531757</td>\n",
       "      <td>0.796962</td>\n",
       "      <td>2.957975</td>\n",
       "      <td>8.619747</td>\n",
       "      <td>1.130033</td>\n",
       "      <td>0.939588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sato_K3</td>\n",
       "      <td>15714</td>\n",
       "      <td>18.481991</td>\n",
       "      <td>77.590398</td>\n",
       "      <td>1.531437</td>\n",
       "      <td>0.801749</td>\n",
       "      <td>3.033713</td>\n",
       "      <td>8.182333</td>\n",
       "      <td>1.127927</td>\n",
       "      <td>0.984825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sato_K4</td>\n",
       "      <td>15753</td>\n",
       "      <td>17.897162</td>\n",
       "      <td>55.324801</td>\n",
       "      <td>1.534120</td>\n",
       "      <td>0.783969</td>\n",
       "      <td>2.924267</td>\n",
       "      <td>7.192327</td>\n",
       "      <td>1.117836</td>\n",
       "      <td>0.568125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sato_multi</td>\n",
       "      <td>78733</td>\n",
       "      <td>18.075444</td>\n",
       "      <td>64.845828</td>\n",
       "      <td>1.531873</td>\n",
       "      <td>0.790966</td>\n",
       "      <td>2.969581</td>\n",
       "      <td>8.295833</td>\n",
       "      <td>1.125335</td>\n",
       "      <td>0.868258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t2d</td>\n",
       "      <td>233</td>\n",
       "      <td>121.600858</td>\n",
       "      <td>115.509022</td>\n",
       "      <td>4.948498</td>\n",
       "      <td>1.793386</td>\n",
       "      <td>1.913527</td>\n",
       "      <td>1.791974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>turl_el</td>\n",
       "      <td>7291</td>\n",
       "      <td>19.883281</td>\n",
       "      <td>14.243179</td>\n",
       "      <td>3.022631</td>\n",
       "      <td>1.113579</td>\n",
       "      <td>1.498448</td>\n",
       "      <td>0.901519</td>\n",
       "      <td>1.008150</td>\n",
       "      <td>0.090829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>turl_el_dev</td>\n",
       "      <td>3636</td>\n",
       "      <td>15.117437</td>\n",
       "      <td>13.106033</td>\n",
       "      <td>2.679868</td>\n",
       "      <td>1.014657</td>\n",
       "      <td>1.587599</td>\n",
       "      <td>1.016828</td>\n",
       "      <td>1.009200</td>\n",
       "      <td>0.097303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>turl_el_test_dev</td>\n",
       "      <td>10927</td>\n",
       "      <td>17.500359</td>\n",
       "      <td>13.674606</td>\n",
       "      <td>2.851249</td>\n",
       "      <td>1.064118</td>\n",
       "      <td>1.543024</td>\n",
       "      <td>0.959173</td>\n",
       "      <td>1.008675</td>\n",
       "      <td>0.094066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>wiki_tabner_final</td>\n",
       "      <td>61273</td>\n",
       "      <td>12.699705</td>\n",
       "      <td>19.893641</td>\n",
       "      <td>5.207302</td>\n",
       "      <td>2.429691</td>\n",
       "      <td>4.606729</td>\n",
       "      <td>16.130030</td>\n",
       "      <td>1.247672</td>\n",
       "      <td>1.371900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              dataset  num_tables  mean_num_rows  std_num_rows  mean_num_cols  \\\n",
       "12             WikiGS       15000      13.783733     35.450495       4.578733   \n",
       "3          git_tables        1101      58.196185     94.693164      16.873751   \n",
       "1              limaye         428      34.549065     40.992761       3.787383   \n",
       "10            sato_K0       15736      17.848310     60.938394       1.530249   \n",
       "4             sato_K1       15754      18.480640     75.620203       1.531801   \n",
       "9             sato_K2       15776      17.669118     54.755346       1.531757   \n",
       "7             sato_K3       15714      18.481991     77.590398       1.531437   \n",
       "8             sato_K4       15753      17.897162     55.324801       1.534120   \n",
       "11         sato_multi       78733      18.075444     64.845828       1.531873   \n",
       "0                 t2d         233     121.600858    115.509022       4.948498   \n",
       "2             turl_el        7291      19.883281     14.243179       3.022631   \n",
       "5         turl_el_dev        3636      15.117437     13.106033       2.679868   \n",
       "6    turl_el_test_dev       10927      17.500359     13.674606       2.851249   \n",
       "13  wiki_tabner_final       61273      12.699705     19.893641       5.207302   \n",
       "\n",
       "    std_num_cols  mean_num_toks  std_num_toks  mean_comma  std_comma  \n",
       "12      3.356179       2.471672      5.704536    1.103979   0.618069  \n",
       "3      11.600740       1.868231     10.062218    1.037563   0.617178  \n",
       "1       1.233917       1.706675      1.392773    1.033316   0.182750  \n",
       "10      0.787049       2.936658      9.177716    1.123136   1.106772  \n",
       "4       0.785103       2.995293      8.307041    1.127742   0.741978  \n",
       "9       0.796962       2.957975      8.619747    1.130033   0.939588  \n",
       "7       0.801749       3.033713      8.182333    1.127927   0.984825  \n",
       "8       0.783969       2.924267      7.192327    1.117836   0.568125  \n",
       "11      0.790966       2.969581      8.295833    1.125335   0.868258  \n",
       "0       1.793386       1.913527      1.791974    1.000000   0.000000  \n",
       "2       1.113579       1.498448      0.901519    1.008150   0.090829  \n",
       "5       1.014657       1.587599      1.016828    1.009200   0.097303  \n",
       "6       1.064118       1.543024      0.959173    1.008675   0.094066  \n",
       "13      2.429691       4.606729     16.130030    1.247672   1.371900  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_stats.sort_values([\"dataset\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dfca2f",
   "metadata": {},
   "source": [
    "### Calculate Welch's T-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8366904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_toks(dfs):\n",
    "    overall_num_toks = []     \n",
    "    for df in dfs:       \n",
    "\n",
    "        for index,row in df.iterrows():\n",
    "            for col in df.columns:               \n",
    "                cell_text = row[col]     \n",
    "                \n",
    "                num_tokens = len([tok for tok in nlp(str(cell_text))])            \n",
    "                overall_num_toks.append(num_tokens)\n",
    "                \n",
    "    return overall_num_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da993e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabner_mean_toks = calc_mean_toks(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dd876d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4358559\n"
     ]
    }
   ],
   "source": [
    "tabner_mean_toks = np.load('tabner_mean_toks.npy')\n",
    "print(len(tabner_mean_toks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7df72bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1041715\n"
     ]
    }
   ],
   "source": [
    "wikigs_mean_toks = np.load('wikigs_mean_toks.npy')\n",
    "print(len(wikigs_mean_toks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc7275f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=223.8981546350554, pvalue=0.0, df=4713311.415947707)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(tabner_mean_toks, wikigs_mean_toks, equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "088efa13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    }
   ],
   "source": [
    "tabner_mean_toks_smaller = tabner_mean_toks[:1000000]\n",
    "print(len(tabner_mean_toks_smaller))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d39c52a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=105.86637750711375, pvalue=0.0, df=1183372.618911697)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(tabner_mean_toks_smaller, wikigs_mean_toks, equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06883bf",
   "metadata": {},
   "source": [
    "### Calculate average num of labeled entities in Wiki-TabNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7e11075",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"../data/Wiki_TabNER_final_labeled.json\"\n",
    "with open(data_path, 'r') as f:\n",
    "    ner_tables = json.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d694deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_cells = 0\n",
    "total_num_ents = 0\n",
    "for i in range(len(ner_tables)):\n",
    "    \n",
    "    num_cells = len(ner_tables[i][0][6])\n",
    "    total_num_cells += num_cells\n",
    "    \n",
    "    for k in range(len(ner_tables[i][0][6])):\n",
    "        num_ents = len(ner_tables[i][0][6][k][0])\n",
    "        total_num_ents+=num_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7c72b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average num of labeled entities per cell 2.0061203005619475\n"
     ]
    }
   ],
   "source": [
    "print(\"Average num of labeled entities per cell {}\".format(total_num_ents/total_num_cells))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca9867d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wikitabner",
   "language": "python",
   "name": "wikitabner"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
